{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "\n",
    "from data_loaders import preproccess_data, generate_scaffold_split, df_to_graph_list, get_scaffolds\n",
    "from graphnn1 import GCN1\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:36:44] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "file_path = 'data/curated-solubility-dataset.csv'\n",
    "df = preproccess_data(file_path)\n",
    "\n",
    "\n",
    "df['scaffold'] = df['mol'].apply(get_scaffolds)\n",
    "\n",
    "# scaffolds to get train, val, text\n",
    "train_idx, val_idx, test_idx = generate_scaffold_split(df)\n",
    "\n",
    "# Split the dataframe into train, val, and test\n",
    "train_df = df.iloc[train_idx]\n",
    "val_df = df.iloc[val_idx]\n",
    "test_df = df.iloc[test_idx]\n",
    "\n",
    "# df to graph list\n",
    "train_graph_list = df_to_graph_list(train_df)\n",
    "val_graph_list = df_to_graph_list(val_df)\n",
    "test_graph_list = df_to_graph_list(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_graph_list, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_graph_list, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_graph_list, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 331.0987, Val RMSE: 4.2636, R^2: -20.2148, CI (95%):[3.9652, 4.5425]\n",
      "Epoch: 2, Train Loss: 36.3586, Val RMSE: 3.2362, R^2: -11.2219, CI (95%):[2.9107, 3.5318]\n",
      "Epoch: 3, Train Loss: 20.6112, Val RMSE: 3.0511, R^2: -9.8640, CI (95%):[2.8019, 3.2814]\n",
      "Epoch: 4, Train Loss: 12.4701, Val RMSE: 2.2234, R^2: -4.7691, CI (95%):[2.0613, 2.3744]\n",
      "Epoch: 5, Train Loss: 7.1693, Val RMSE: 1.9541, R^2: -3.4562, CI (95%):[1.7825, 2.1118]\n",
      "Epoch: 6, Train Loss: 4.5955, Val RMSE: 1.5152, R^2: -1.6794, CI (95%):[1.4201, 1.6047]\n",
      "Epoch: 7, Train Loss: 2.4687, Val RMSE: 1.0116, R^2: -0.1941, CI (95%):[0.9346, 1.0830]\n",
      "Epoch: 8, Train Loss: 1.4673, Val RMSE: 0.8270, R^2: 0.2018, CI (95%):[0.7658, 0.8840]\n",
      "Epoch: 9, Train Loss: 1.0398, Val RMSE: 0.7148, R^2: 0.4038, CI (95%):[0.6668, 0.7598]\n",
      "Epoch: 10, Train Loss: 0.7966, Val RMSE: 0.6817, R^2: 0.4577, CI (95%):[0.6397, 0.7213]\n",
      "Epoch: 11, Train Loss: 0.6935, Val RMSE: 0.6281, R^2: 0.5396, CI (95%):[0.5964, 0.6582]\n",
      "Epoch: 12, Train Loss: 0.6264, Val RMSE: 0.6151, R^2: 0.5585, CI (95%):[0.5833, 0.6452]\n",
      "Epoch: 13, Train Loss: 0.5820, Val RMSE: 0.6081, R^2: 0.5685, CI (95%):[0.5792, 0.6357]\n",
      "Epoch: 14, Train Loss: 0.5500, Val RMSE: 0.5848, R^2: 0.6008, CI (95%):[0.5551, 0.6132]\n",
      "Epoch: 15, Train Loss: 0.5166, Val RMSE: 0.6023, R^2: 0.5766, CI (95%):[0.5712, 0.6319]\n",
      "Epoch: 16, Train Loss: 0.4935, Val RMSE: 0.5763, R^2: 0.6123, CI (95%):[0.5471, 0.6042]\n",
      "Epoch: 17, Train Loss: 0.4755, Val RMSE: 0.6031, R^2: 0.5756, CI (95%):[0.5739, 0.6309]\n",
      "Epoch: 18, Train Loss: 0.4644, Val RMSE: 0.5895, R^2: 0.5944, CI (95%):[0.5592, 0.6183]\n",
      "Epoch: 19, Train Loss: 0.4635, Val RMSE: 0.5619, R^2: 0.6315, CI (95%):[0.5336, 0.5888]\n",
      "Epoch: 20, Train Loss: 0.4504, Val RMSE: 0.5716, R^2: 0.6187, CI (95%):[0.5438, 0.5982]\n",
      "Epoch: 21, Train Loss: 0.4564, Val RMSE: 0.8946, R^2: 0.0660, CI (95%):[0.8590, 0.9288]\n",
      "Epoch: 22, Train Loss: 0.4537, Val RMSE: 0.6092, R^2: 0.5669, CI (95%):[0.5798, 0.6373]\n",
      "Epoch: 23, Train Loss: 0.7753, Val RMSE: 0.6369, R^2: 0.5266, CI (95%):[0.6051, 0.6672]\n",
      "Epoch: 24, Train Loss: 0.6665, Val RMSE: 0.6334, R^2: 0.5318, CI (95%):[0.6037, 0.6618]\n",
      "Epoch: 25, Train Loss: 0.6779, Val RMSE: 0.5842, R^2: 0.6017, CI (95%):[0.5556, 0.6114]\n",
      "Epoch: 26, Train Loss: 0.7020, Val RMSE: 0.7287, R^2: 0.3804, CI (95%):[0.6958, 0.7601]\n",
      "Epoch: 27, Train Loss: 0.7808, Val RMSE: 0.6344, R^2: 0.5304, CI (95%):[0.6036, 0.6637]\n",
      "Epoch: 28, Train Loss: 1.3108, Val RMSE: 0.7663, R^2: 0.3146, CI (95%):[0.7315, 0.7997]\n",
      "Epoch: 29, Train Loss: 0.6117, Val RMSE: 0.5896, R^2: 0.5944, CI (95%):[0.5600, 0.6178]\n",
      "Epoch: 30, Train Loss: 0.6284, Val RMSE: 0.8902, R^2: 0.0751, CI (95%):[0.8566, 0.9226]\n",
      "Epoch: 31, Train Loss: 0.5298, Val RMSE: 0.5635, R^2: 0.6294, CI (95%):[0.5344, 0.5913]\n",
      "Epoch: 32, Train Loss: 0.4823, Val RMSE: 0.6010, R^2: 0.5785, CI (95%):[0.5701, 0.6304]\n",
      "Epoch: 33, Train Loss: 0.4938, Val RMSE: 0.6409, R^2: 0.5207, CI (95%):[0.6124, 0.6682]\n",
      "Epoch: 34, Train Loss: 0.4869, Val RMSE: 0.5711, R^2: 0.6194, CI (95%):[0.5432, 0.5977]\n",
      "Epoch: 35, Train Loss: 0.4860, Val RMSE: 0.5746, R^2: 0.6147, CI (95%):[0.5434, 0.6041]\n",
      "Epoch: 36, Train Loss: 0.6255, Val RMSE: 0.6042, R^2: 0.5740, CI (95%):[0.5748, 0.6321]\n",
      "Epoch: 37, Train Loss: 0.4589, Val RMSE: 0.6123, R^2: 0.5624, CI (95%):[0.5790, 0.6440]\n",
      "Epoch: 38, Train Loss: 0.6398, Val RMSE: 0.5590, R^2: 0.6354, CI (95%):[0.5303, 0.5862]\n",
      "Epoch: 39, Train Loss: 0.6932, Val RMSE: 0.5632, R^2: 0.6298, CI (95%):[0.5335, 0.5915]\n",
      "Epoch: 40, Train Loss: 0.4529, Val RMSE: 0.9448, R^2: -0.0418, CI (95%):[0.8975, 0.9899]\n",
      "Epoch: 41, Train Loss: 0.7603, Val RMSE: 0.5541, R^2: 0.6418, CI (95%):[0.5239, 0.5827]\n",
      "Epoch: 42, Train Loss: 0.5363, Val RMSE: 0.5690, R^2: 0.6222, CI (95%):[0.5375, 0.5988]\n",
      "Epoch: 43, Train Loss: 0.4956, Val RMSE: 0.6224, R^2: 0.5479, CI (95%):[0.5931, 0.6505]\n",
      "Epoch: 44, Train Loss: 0.4327, Val RMSE: 0.6169, R^2: 0.5558, CI (95%):[0.5792, 0.6525]\n",
      "Epoch: 45, Train Loss: 0.7040, Val RMSE: 0.5409, R^2: 0.6586, CI (95%):[0.5097, 0.5704]\n",
      "Epoch: 46, Train Loss: 1.0112, Val RMSE: 0.5710, R^2: 0.6195, CI (95%):[0.5394, 0.6010]\n",
      "Epoch: 47, Train Loss: 0.4320, Val RMSE: 0.5547, R^2: 0.6409, CI (95%):[0.5241, 0.5838]\n",
      "Epoch: 48, Train Loss: 0.4417, Val RMSE: 0.5791, R^2: 0.6086, CI (95%):[0.5473, 0.6093]\n",
      "Epoch: 49, Train Loss: 0.4037, Val RMSE: 0.5878, R^2: 0.5968, CI (95%):[0.5532, 0.6204]\n",
      "Epoch: 50, Train Loss: 0.3957, Val RMSE: 0.5735, R^2: 0.6162, CI (95%):[0.5434, 0.6021]\n",
      "Epoch: 51, Train Loss: 0.5944, Val RMSE: 0.5956, R^2: 0.5861, CI (95%):[0.5635, 0.6260]\n",
      "Epoch: 52, Train Loss: 0.4929, Val RMSE: 0.5954, R^2: 0.5863, CI (95%):[0.5660, 0.6235]\n",
      "Epoch: 53, Train Loss: 0.9705, Val RMSE: 0.6133, R^2: 0.5610, CI (95%):[0.5844, 0.6410]\n",
      "Epoch: 54, Train Loss: 0.5085, Val RMSE: 0.6027, R^2: 0.5760, CI (95%):[0.5706, 0.6333]\n",
      "Epoch: 55, Train Loss: 0.5605, Val RMSE: 0.6175, R^2: 0.5549, CI (95%):[0.5881, 0.6456]\n",
      "Epoch: 56, Train Loss: 0.5269, Val RMSE: 0.7667, R^2: 0.3141, CI (95%):[0.7302, 0.8015]\n",
      "Epoch: 57, Train Loss: 0.4299, Val RMSE: 0.5829, R^2: 0.6035, CI (95%):[0.5540, 0.6104]\n",
      "Epoch: 58, Train Loss: 0.3998, Val RMSE: 0.5918, R^2: 0.5913, CI (95%):[0.5585, 0.6233]\n",
      "Epoch: 59, Train Loss: 0.4252, Val RMSE: 0.5709, R^2: 0.6196, CI (95%):[0.5408, 0.5996]\n",
      "Epoch: 60, Train Loss: 0.4067, Val RMSE: 0.8454, R^2: 0.1659, CI (95%):[0.8082, 0.8811]\n",
      "Epoch: 61, Train Loss: 0.5200, Val RMSE: 0.5640, R^2: 0.6288, CI (95%):[0.5357, 0.5909]\n",
      "Epoch: 62, Train Loss: 0.5176, Val RMSE: 0.5598, R^2: 0.6343, CI (95%):[0.5245, 0.5930]\n",
      "Epoch: 63, Train Loss: 1.1912, Val RMSE: 0.6176, R^2: 0.5549, CI (95%):[0.5859, 0.6477]\n",
      "Epoch: 64, Train Loss: 1.0759, Val RMSE: 0.6140, R^2: 0.5600, CI (95%):[0.5796, 0.6466]\n",
      "Epoch: 65, Train Loss: 0.4521, Val RMSE: 0.6057, R^2: 0.5719, CI (95%):[0.5770, 0.6331]\n",
      "Epoch: 66, Train Loss: 0.7425, Val RMSE: 0.5709, R^2: 0.6197, CI (95%):[0.5388, 0.6012]\n",
      "Epoch: 67, Train Loss: 0.5174, Val RMSE: 0.5553, R^2: 0.6401, CI (95%):[0.5248, 0.5842]\n",
      "Epoch: 68, Train Loss: 0.4095, Val RMSE: 0.6349, R^2: 0.5296, CI (95%):[0.6048, 0.6636]\n",
      "Epoch: 69, Train Loss: 0.4117, Val RMSE: 0.7886, R^2: 0.2742, CI (95%):[0.7484, 0.8268]\n",
      "Epoch: 70, Train Loss: 0.5877, Val RMSE: 0.5681, R^2: 0.6234, CI (95%):[0.5383, 0.5964]\n",
      "Epoch: 71, Train Loss: 0.4651, Val RMSE: 0.6439, R^2: 0.5161, CI (95%):[0.6095, 0.6766]\n",
      "Epoch: 72, Train Loss: 0.3891, Val RMSE: 0.5464, R^2: 0.6516, CI (95%):[0.5164, 0.5748]\n",
      "Epoch: 73, Train Loss: 0.3240, Val RMSE: 0.6022, R^2: 0.5768, CI (95%):[0.5730, 0.6300]\n",
      "Epoch: 74, Train Loss: 0.3703, Val RMSE: 1.1841, R^2: -0.6363, CI (95%):[1.1157, 1.2488]\n",
      "Epoch: 75, Train Loss: 1.5374, Val RMSE: 0.6670, R^2: 0.4807, CI (95%):[0.6341, 0.6984]\n",
      "Epoch: 76, Train Loss: 0.4268, Val RMSE: 0.6223, R^2: 0.5480, CI (95%):[0.5922, 0.6510]\n",
      "Epoch: 77, Train Loss: 0.4836, Val RMSE: 0.5763, R^2: 0.6123, CI (95%):[0.5468, 0.6045]\n",
      "Epoch: 78, Train Loss: 0.3647, Val RMSE: 0.6722, R^2: 0.4727, CI (95%):[0.6354, 0.7071]\n",
      "Epoch: 79, Train Loss: 0.3823, Val RMSE: 0.6407, R^2: 0.5210, CI (95%):[0.6067, 0.6729]\n",
      "Epoch: 80, Train Loss: 0.4070, Val RMSE: 0.5709, R^2: 0.6197, CI (95%):[0.5439, 0.5966]\n",
      "Epoch: 81, Train Loss: 0.3211, Val RMSE: 0.5608, R^2: 0.6330, CI (95%):[0.5298, 0.5902]\n",
      "Epoch: 82, Train Loss: 0.4286, Val RMSE: 0.5584, R^2: 0.6361, CI (95%):[0.5251, 0.5899]\n",
      "Epoch: 83, Train Loss: 0.7865, Val RMSE: 0.5751, R^2: 0.6141, CI (95%):[0.5479, 0.6010]\n",
      "Epoch: 84, Train Loss: 0.5795, Val RMSE: 0.5471, R^2: 0.6507, CI (95%):[0.5189, 0.5739]\n",
      "Epoch: 85, Train Loss: 0.3578, Val RMSE: 0.5632, R^2: 0.6298, CI (95%):[0.5357, 0.5895]\n",
      "Epoch: 86, Train Loss: 0.4707, Val RMSE: 0.5269, R^2: 0.6761, CI (95%):[0.4969, 0.5552]\n",
      "Epoch: 87, Train Loss: 0.3047, Val RMSE: 0.6361, R^2: 0.5278, CI (95%):[0.6004, 0.6699]\n",
      "Epoch: 88, Train Loss: 0.3572, Val RMSE: 0.5902, R^2: 0.5935, CI (95%):[0.5580, 0.6208]\n",
      "Epoch: 89, Train Loss: 0.4717, Val RMSE: 0.7610, R^2: 0.3242, CI (95%):[0.7272, 0.7933]\n",
      "Epoch: 90, Train Loss: 0.3503, Val RMSE: 0.5561, R^2: 0.6392, CI (95%):[0.5240, 0.5863]\n",
      "Epoch: 91, Train Loss: 0.3231, Val RMSE: 0.5376, R^2: 0.6627, CI (95%):[0.5079, 0.5657]\n",
      "Epoch: 92, Train Loss: 0.3163, Val RMSE: 0.6308, R^2: 0.5356, CI (95%):[0.6002, 0.6601]\n",
      "Epoch: 93, Train Loss: 0.3175, Val RMSE: 0.5506, R^2: 0.6462, CI (95%):[0.5187, 0.5807]\n",
      "Epoch: 94, Train Loss: 0.7523, Val RMSE: 0.8794, R^2: 0.0976, CI (95%):[0.8417, 0.9154]\n",
      "Epoch: 95, Train Loss: 0.7441, Val RMSE: 0.6136, R^2: 0.5606, CI (95%):[0.5822, 0.6435]\n",
      "Epoch: 96, Train Loss: 0.8538, Val RMSE: 0.5772, R^2: 0.6111, CI (95%):[0.5471, 0.6059]\n",
      "Epoch: 97, Train Loss: 0.6668, Val RMSE: 0.5607, R^2: 0.6332, CI (95%):[0.5329, 0.5871]\n",
      "Epoch: 98, Train Loss: 0.5017, Val RMSE: 0.6297, R^2: 0.5372, CI (95%):[0.5987, 0.6593]\n",
      "Epoch: 99, Train Loss: 0.6311, Val RMSE: 0.8361, R^2: 0.1841, CI (95%):[0.8010, 0.8699]\n",
      "Epoch: 100, Train Loss: 0.6916, Val RMSE: 0.6765, R^2: 0.4659, CI (95%):[0.6458, 0.7058]\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "num_node = train_graph_list[0].x.shape[1]\n",
    "edge_attr = train_graph_list[0].edge_attr.shape[1]\n",
    "u_d = train_graph_list[0].u.shape[1]\n",
    "\n",
    "model = GCN1(num_node_features=num_node,\n",
    "            edge_attr_dim=edge_attr,\n",
    "            u_dim=u_d, \n",
    "            hidden_dim=64, \n",
    "            output_dim=1).to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100  \n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        target = data.y.view(data.num_graphs, -1).to(device)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * data.num_graphs\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    all_preds, all_targets = [], []\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            target = data.y.view(data.num_graphs, -1).to(device)\n",
    "            loss = criterion(output, target) #get loss based on criterion\n",
    "            val_loss += loss.item() * data.num_graphs\n",
    "            all_preds.extend(output.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "    val_loss /= len(val_loader.dataset) #compute validation loss\n",
    "    val_rmse = val_loss ** 0.5\n",
    "    \n",
    "    # Compute R^2\n",
    "    all_preds = np.array(all_preds).flatten()\n",
    "    all_targets = np.array(all_targets).flatten()\n",
    "    r2 = r2_score(all_targets, all_preds)\n",
    "\n",
    "    # Compute 95% Confidence Interval for RMSE\n",
    "    confidence = 0.95\n",
    "    squared_errors = (all_preds - all_targets) ** 2\n",
    "    mean_se = np.mean(squared_errors)\n",
    "    se = stats.sem(squared_errors)\n",
    "    interval = stats.t.interval(confidence, len(squared_errors)-1, loc=mean_se, scale=se)\n",
    "    ci_lower, ci_upper = np.sqrt(interval[0]), np.sqrt(interval[1])\n",
    "    \n",
    "    print(f\"Epoch: {epoch}, Train Loss: {train_loss:.4f}, Val RMSE: {val_rmse:.4f}, R²: {r2:.4f}, CI (95%):[{ci_lower:.4f}, {ci_upper:.4f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.7463, R²: 0.1641, CI (95%): [0.7122, 0.7789]\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "all_preds, all_targets = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        target = data.y.view(data.num_graphs, -1).to(device)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss += loss.item() * data.num_graphs\n",
    "        all_preds.extend(output.cpu().numpy())\n",
    "        all_targets.extend(target.cpu().numpy())\n",
    "test_loss /= len(test_loader.dataset)\n",
    "test_rmse = test_loss ** 0.5\n",
    "\n",
    "# Compute R^2\n",
    "all_preds = np.array(all_preds).flatten()\n",
    "all_targets = np.array(all_targets).flatten()\n",
    "r2 = r2_score(all_targets, all_preds)\n",
    "\n",
    "# Compute 95% Confidence Interval for RMSE\n",
    "confidence = 0.95\n",
    "squared_errors = (all_preds - all_targets) ** 2\n",
    "mean_se = np.mean(squared_errors)\n",
    "se = stats.sem(squared_errors)\n",
    "interval = stats.t.interval(confidence, len(squared_errors)-1, loc=mean_se, scale=se)\n",
    "ci_lower, ci_upper = np.sqrt(interval[0]), np.sqrt(interval[1])\n",
    "\n",
    "print(f\"Test RMSE: {test_rmse:.4f}, R²: {r2:.4f}, CI (95%): [{ci_lower:.4f}, {ci_upper:.4f}]\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
